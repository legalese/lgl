#+TITLE: LGL SDK TESTS

* Quickstart

Usage:

#+BEGIN_EXAMPLE
sh lgltest-dev.sh
sh lgltest-prod.sh
#+END_EXAMPLE

* Testing the lgl executable

The lgl executable is the preferred way to exercise back-end functionality. It's what users use, so we use it too.

This test suite runs the lgl executable against a range of environment
variables, command-line parameters, and STDIN inputs. For each input,
we expect certain output. Now you're thinking functionally!

First we set up a master directory to contain the output of one or more test runs.

A test run operates against a specific endpoint, using a specific protocol version, operating one or more service families.

Together, multiple runs will provide complete test coverage.

** How tests pass or fail

The results of each test are saved into ~*.out~ (for STDOUT) and ~*.err~ for (STDERR) files.

Then directory's run output is diffed against a known reference set of expectations.

If reference is equivalent to the output, the test passes.

** Setting up the Test-Run Master Directory

A test run starts at a particular point in time. We create a directory accordingly.

#+NAME: lgltest-setup-common
#+BEGIN_SRC sh :eval no :noweb yes :noweb-sep ""
# do not edit *.sh files! they are automatically tangled out of tests/README.org with C-c C-v t

testdir=testruns/`date +%Y%m%d-%H%M%S`
echo "*** saving to $testdir"
mkdir -p $testdir
cd $testdir
#+END_SRC

Within that master directory, we may create one or more subdirectories to represent specific combinations of endpoint and version.

Within those subdirectories, we create one or more files; each file represents a particular test point, a particular ~lgl~ invocation.

** Dimensions of Test Coverage

To achieve full coverage we need to take every point in test space across the following dimensions:

*** liveness: development / production
:PROPERTIES:
:header-args: :noweb-ref liveness
:END:

**** development
#+NAME: liveness_development
| local | http://localhost/api   |

**** production
#+NAME: liveness_production
| v2  | https://legalese.com/api                     |
| 1a  | https://ap-southeast-1a-api.legalese.com/api |
| 1b  | https://ap-southeast-1b-api.legalese.com/api |
| api | https://api.legalese.com/api                 |

*** version: 0.9 / 1.0 / 1.1

#+NAME: version
| v0.9 | --version=0.9  |
| v1.0 | --version=0.9  |
| v1.1 |                |

*** command line arguments
:PROPERTIES:
:header-args: :noweb-ref arguments
:END:

lgl takes arguments. We invoke it differently and see if each run matches expectations.

Each test run is operated out of a shell script. The essence of each shell script looks like this:

**** basics: help / account setup
:PROPERTIES:
:header-args: :noweb-ref basics
:END:

Before we get into the meat of the testing we see if the basics are in place.

***** help

First we make sure ~lgl~ is properly installed, and responding to cries for ~help~.

#+BEGIN_SRC sh :noweb yes :exports results :results output :noweb-sep ""
<<mkCapture(myargs="help")>>
#+END_SRC

#+RESULTS:

***** -t init

We set up some test credentials. Without them, the rest of the tests wouldn't work.

#+BEGIN_SRC sh :noweb yes :exports results :results verbatim :eval no :noweb-sep ""
<<mkCapture(myargs="init -t")>>
#+END_SRC

This should succeed with:

#+RESULTS:
: You have set up a Legalese account with test credentials.
: Those credentials have been saved to lglconfig.json
: Commands will work with limited functionality for demo purposes.
: When you are ready to use the system for real,
:   rm lglconfig.json
:   lgl init <email>
: 

If it fails, we get

#+RESULTS:
: lgl: init: config file lglconfig.json already exists; refusing to init.
:     If you are sure you want to re-initialize,
:     and you are prepared to create a new account with a different email address,
:     delete lglconfig.json and run init again with the new email address.
:     Or just go to a different directory, without a lglconfig.json file, and lgl init.


**** service families: proforma / bizfile / workflow

Finally we get into the test of each service.

#+NAME: service
| proforma schemalist             | corpsec |                                       |
| proforma schemalist hw3         | corpsec |                                       |
| proforma schemalist hw3 example | corpsec |                                       |
| proforma schema hw3             | corpsec |                                       |
| proforma generate hw3           | corpsec | < proforma-schemalist-hw3-example.out |
| proforma generate hw3 hw3.pdf   | corpsec | < proforma-schemalist-hw3-example.out |
| proforma generate hw3 hw3.docx  | corpsec | < proforma-schemalist-hw3-example.out |
| bizfile search prive            | corpsec |                                       |
| bizfile uen 111111111M          | corpsec |                                       |
| bizfile uen 201527692R          | corpsec |                                       |

JKL Technologies is a fictitious ACRA APImall Sandbox company. Queries about that UEN don't get billed.

** Putting it all together: Infrastructure & Utilities

We set up one test script for development testing; this can be used for TDD.

We set up one test script for production testing; this is used for DevOps.

*** Populating the test points

#+NAME: range-liveness-version
#+BEGIN_SRC python :noweb yes :exports results :results output :var liveness=liveness_development :var version=version :var service=service
  import re
  lgl_uri = ""
  for l in liveness:
    for v in version:
      print("subdir=%s/%s; mkdir -p $subdir; cd $subdir;" % (l[0], v[0]))
      print("echo \"*** testing %s/%s\"" % (l[0], v[0]))
      for s in service:
        if lgl_uri != "%s/%s/%s" % (l[1],s[1],v[0]):
          lgl_uri = "%s/%s/%s" % (l[1],s[1],v[0])
          print("export LGL_URI=%s" % lgl_uri)
        if re.match(r'bizfile', s[0]) and v[0] != 'v1.1': continue
        dashed = s[0].replace(" ","-")
        print("echo   LGL_URI=%s/%s/%s lgl %s %s %s > %s.run" %
              (l[1], s[1], v[0],    v[1], s[0], s[2], dashed))
        print("lgl %s %s %s > %s.out 2> %s.err" %
              (v[1], s[0], s[2], dashed, dashed))
      print("cd ../..")
#+END_SRC

#+RESULTS: range-liveness-version
#+begin_example
subdir=local/v0.9; mkdir -p $subdir; cd $subdir;
echo "*** testing local/v0.9"
export LGL_URI=http://localhost/api/corpsec/v0.9
echo   LGL_URI=http://localhost/api/corpsec/v0.9 lgl --version=0.9 proforma schemalist  > proforma-schemalist.run
lgl --version=0.9 proforma schemalist  > proforma-schemalist.out 2> proforma-schemalist.err
echo   LGL_URI=http://localhost/api/corpsec/v0.9 lgl --version=0.9 proforma schemalist hw3  > proforma-schemalist-hw3.run
lgl --version=0.9 proforma schemalist hw3  > proforma-schemalist-hw3.out 2> proforma-schemalist-hw3.err
echo   LGL_URI=http://localhost/api/corpsec/v0.9 lgl --version=0.9 proforma schemalist hw3 example  > proforma-schemalist-hw3-example.run
lgl --version=0.9 proforma schemalist hw3 example  > proforma-schemalist-hw3-example.out 2> proforma-schemalist-hw3-example.err
echo   LGL_URI=http://localhost/api/corpsec/v0.9 lgl --version=0.9 proforma schema hw3  > proforma-schema-hw3.run
lgl --version=0.9 proforma schema hw3  > proforma-schema-hw3.out 2> proforma-schema-hw3.err
echo   LGL_URI=http://localhost/api/corpsec/v0.9 lgl --version=0.9 proforma generate hw3 < proforma-schemalist-hw3-example.out > proforma-generate-hw3.run
lgl --version=0.9 proforma generate hw3 < proforma-schemalist-hw3-example.out > proforma-generate-hw3.out 2> proforma-generate-hw3.err
echo   LGL_URI=http://localhost/api/corpsec/v0.9 lgl --version=0.9 proforma generate hw3 hw3.pdf < proforma-schemalist-hw3-example.out > proforma-generate-hw3-hw3.pdf.run
lgl --version=0.9 proforma generate hw3 hw3.pdf < proforma-schemalist-hw3-example.out > proforma-generate-hw3-hw3.pdf.out 2> proforma-generate-hw3-hw3.pdf.err
echo   LGL_URI=http://localhost/api/corpsec/v0.9 lgl --version=0.9 proforma generate hw3 hw3.docx < proforma-schemalist-hw3-example.out > proforma-generate-hw3-hw3.docx.run
lgl --version=0.9 proforma generate hw3 hw3.docx < proforma-schemalist-hw3-example.out > proforma-generate-hw3-hw3.docx.out 2> proforma-generate-hw3-hw3.docx.err
cd ../..
subdir=local/v1.0; mkdir -p $subdir; cd $subdir;
echo "*** testing local/v1.0"
export LGL_URI=http://localhost/api/corpsec/v1.0
echo   LGL_URI=http://localhost/api/corpsec/v1.0 lgl --version=0.9 proforma schemalist  > proforma-schemalist.run
lgl --version=0.9 proforma schemalist  > proforma-schemalist.out 2> proforma-schemalist.err
echo   LGL_URI=http://localhost/api/corpsec/v1.0 lgl --version=0.9 proforma schemalist hw3  > proforma-schemalist-hw3.run
lgl --version=0.9 proforma schemalist hw3  > proforma-schemalist-hw3.out 2> proforma-schemalist-hw3.err
echo   LGL_URI=http://localhost/api/corpsec/v1.0 lgl --version=0.9 proforma schemalist hw3 example  > proforma-schemalist-hw3-example.run
lgl --version=0.9 proforma schemalist hw3 example  > proforma-schemalist-hw3-example.out 2> proforma-schemalist-hw3-example.err
echo   LGL_URI=http://localhost/api/corpsec/v1.0 lgl --version=0.9 proforma schema hw3  > proforma-schema-hw3.run
lgl --version=0.9 proforma schema hw3  > proforma-schema-hw3.out 2> proforma-schema-hw3.err
echo   LGL_URI=http://localhost/api/corpsec/v1.0 lgl --version=0.9 proforma generate hw3 < proforma-schemalist-hw3-example.out > proforma-generate-hw3.run
lgl --version=0.9 proforma generate hw3 < proforma-schemalist-hw3-example.out > proforma-generate-hw3.out 2> proforma-generate-hw3.err
echo   LGL_URI=http://localhost/api/corpsec/v1.0 lgl --version=0.9 proforma generate hw3 hw3.pdf < proforma-schemalist-hw3-example.out > proforma-generate-hw3-hw3.pdf.run
lgl --version=0.9 proforma generate hw3 hw3.pdf < proforma-schemalist-hw3-example.out > proforma-generate-hw3-hw3.pdf.out 2> proforma-generate-hw3-hw3.pdf.err
echo   LGL_URI=http://localhost/api/corpsec/v1.0 lgl --version=0.9 proforma generate hw3 hw3.docx < proforma-schemalist-hw3-example.out > proforma-generate-hw3-hw3.docx.run
lgl --version=0.9 proforma generate hw3 hw3.docx < proforma-schemalist-hw3-example.out > proforma-generate-hw3-hw3.docx.out 2> proforma-generate-hw3-hw3.docx.err
cd ../..
subdir=local/v1.1; mkdir -p $subdir; cd $subdir;
echo "*** testing local/v1.1"
export LGL_URI=http://localhost/api/corpsec/v1.1
echo   LGL_URI=http://localhost/api/corpsec/v1.1 lgl  proforma schemalist  > proforma-schemalist.run
lgl  proforma schemalist  > proforma-schemalist.out 2> proforma-schemalist.err
echo   LGL_URI=http://localhost/api/corpsec/v1.1 lgl  proforma schemalist hw3  > proforma-schemalist-hw3.run
lgl  proforma schemalist hw3  > proforma-schemalist-hw3.out 2> proforma-schemalist-hw3.err
echo   LGL_URI=http://localhost/api/corpsec/v1.1 lgl  proforma schemalist hw3 example  > proforma-schemalist-hw3-example.run
lgl  proforma schemalist hw3 example  > proforma-schemalist-hw3-example.out 2> proforma-schemalist-hw3-example.err
echo   LGL_URI=http://localhost/api/corpsec/v1.1 lgl  proforma schema hw3  > proforma-schema-hw3.run
lgl  proforma schema hw3  > proforma-schema-hw3.out 2> proforma-schema-hw3.err
echo   LGL_URI=http://localhost/api/corpsec/v1.1 lgl  proforma generate hw3 < proforma-schemalist-hw3-example.out > proforma-generate-hw3.run
lgl  proforma generate hw3 < proforma-schemalist-hw3-example.out > proforma-generate-hw3.out 2> proforma-generate-hw3.err
echo   LGL_URI=http://localhost/api/corpsec/v1.1 lgl  proforma generate hw3 hw3.pdf < proforma-schemalist-hw3-example.out > proforma-generate-hw3-hw3.pdf.run
lgl  proforma generate hw3 hw3.pdf < proforma-schemalist-hw3-example.out > proforma-generate-hw3-hw3.pdf.out 2> proforma-generate-hw3-hw3.pdf.err
echo   LGL_URI=http://localhost/api/corpsec/v1.1 lgl  proforma generate hw3 hw3.docx < proforma-schemalist-hw3-example.out > proforma-generate-hw3-hw3.docx.run
lgl  proforma generate hw3 hw3.docx < proforma-schemalist-hw3-example.out > proforma-generate-hw3-hw3.docx.out 2> proforma-generate-hw3-hw3.docx.err
echo   LGL_URI=http://localhost/api/corpsec/v1.1 lgl  bizfile search prive  > bizfile-search-prive.run
lgl  bizfile search prive  > bizfile-search-prive.out 2> bizfile-search-prive.err
echo   LGL_URI=http://localhost/api/corpsec/v1.1 lgl  bizfile uen 111111111M  > bizfile-uen-111111111M.run
lgl  bizfile uen 111111111M  > bizfile-uen-111111111M.out 2> bizfile-uen-111111111M.err
cd ../..
>>>
#+end_example

#+NAME: test-prod
#+BEGIN_SRC sh  :shebang #!/bin/bash :noweb yes :tangle lgltest-prod.sh :eval no
<<lgltest-setup-common>>
<<extended_proforma_testing_top>>
<<basics>>
<<range-liveness-version(liveness=liveness_production)>>
<<extended_proforma_testing_main>>
<<test-diff(liveness=liveness_production)>>
<<diff-liveness-dirs(liveness=liveness_production)>>
#+END_SRC

#+NAME: test-dev
#+BEGIN_SRC sh  :shebang #!/bin/bash :noweb yes :tangle lgltest-dev.sh :eval no
<<lgltest-setup-common>>
<<extended_proforma_testing_top>>
<<basics>>
<<range-liveness-version(liveness=liveness_development)>>
<<extended_proforma_testing_main>>
<<test-diff(liveness=liveness_development)>>
<<diff-liveness-dirs(liveness=liveness_development)>>
#+END_SRC

#+NAME: lgl
#+BEGIN_SRC python :noweb yes :exports results :results output :var myargs="help"
print('lgl %s 2>&1' % (myargs))
#+END_SRC

#+NAME: mkCapture
#+BEGIN_SRC python :noweb yes :exports results :results output :var myargs="noargs"
dashed = myargs.replace(" ","-")
print('lgl %s > %s.out 2> %s.err' % (myargs, dashed, dashed))
#+END_SRC

The actual test script combines all of the above.

After running the tests, we compare to see if the output of the tests match the expectations.
*** Comparing the test run with the expected file

**** Ignoring irrelevant differences

Comparing byte-for-byte we will always see differences in the docx and PDFs, because:

#+BEGIN_EXAMPLE
20190903-21:31:21 mengwong@venice4:~/src/l/npm/lglsdk/tests% diff --text reference-20190903/local-v0.9/hw3.pdf testruns/20190903-213015/local-v0.9/hw3.pdf
150c150
< /CreationDate(D:20190903132901Z')>>
---
> /CreationDate(D:20190903133022Z')>>
172,174c172,174
< /ID [ <ED1F658537DCED856D4A956206779527>
< <ED1F658537DCED856D4A956206779527> ]
< /DocChecksum /2C581B5C5A254F920B845125D13844C9
---
> /ID [ <8ACFAAD070DCD323E01E89077CBFBF16>
> <8ACFAAD070DCD323E01E89077CBFBF16> ]
> /DocChecksum /7C6B9646DC6645427BD557B0B4958BAC
20190903-21:31:21 mengwong@venice4:~/src/l/npm/lglsdk/tests%
#+END_EXAMPLE

We need to reduce the reference directory and the testrun directory to equivalence classes by ignoring these differences.

#+NAME: test-diff
#+BEGIN_SRC python :noweb yes :exports results :results output :var ref="reference-20190903" :var liveness=liveness_development :var version=version
print("cd ../..")
myre = '^/CreationDate|^/ID \\[|^<.*> \\]|^/DocChecksum'
for v in version:
  print("egrep -a -v \"%s\" < %s/%s/hw3.pdf > %s/%s/hw3.pdfsimple" % (myre, ref, v[0], ref, v[0]))
  if v[0] == "v1.1":
    print("perl -ni -le 'print unless /datePulled/' %s/%s/bizfile*.out" % (ref, v[0]))
  for l in liveness:
    print("egrep -a -v \"%s\" < $testdir/%s/%s/hw3.pdf > $testdir/%s/%s/hw3.pdfsimple" % (myre, l[0], v[0], l[0], v[0]))
    if v[0] == "v1.1":
      print("perl -ni -le 'print unless /datePulled/' $testdir/%s/%s/bizfile*.out" % (l[0],v[0]))
#+END_SRC

So we ignore any diffs complaining about ~.pdf~ and ~.docx~, and we only care about diffs complaining about ~.pdfsimple~.

And we get rid of datePulled from the bizfile output.

#+RESULTS: test-diff
: hello, world

**** Comparing each directory

#+NAME: diff-liveness-dirs
#+BEGIN_SRC python :noweb yes :exports results :results output :var liveness=liveness_development :var ref="reference-20190903" :var version=version
import re
for l in liveness:
  print("diff -x \*.docx -x \*.pdf -x \*.run -x \*generate\*.out -qru %s/ $testdir/%s/ > $testdir/failures-%s.txt" % (ref, l[0], l[0]))
  print("diff -sqru %s/ $testdir/%s/ > $testdir/identicals-%s.txt" % (ref, l[0], l[0]))
  for v in version:
    print("for binary in %s/%s/*.{docx,pdf};" % (ref,v[0])) ;
    print("  do filename=`basename $binary`;")
    print("     if [ $(stat -f \"%%z\" $binary) = $(stat -f \"%%z\" $testdir/%s/%s/$filename) ];" % (l[0],v[0]))
 #  print("        then echo \" ** file sizes are the same for $filename\";")
    print("        then :; # no-op")
    print("        else echo \" !! file sizes differ for %s/%s/$filename\";" % (l[0],v[0]))
    print("             ls -l $binary %s/%s/$filename | tee failures-%s-%s-$filename.txt; fi; done" % (l[0],v[0],l[0],v[0]))

print("onoes=\"\"; for f in $testdir/failures-*.txt; do if [ -s $f ]; then onoes=\"$onoes $f\"; fi; done")
print("if [ -n \"$onoes\" ]; then count=`cat $testdir/failures-*.txt | wc -l`; echo \"!!! $count tests failed!\"; ls -l $testdir/failures-*.txt; echo ""; cat $testdir/failures-*.txt; else echo \"*** all tests passed!\"; fi");
#+END_SRC

#+RESULTS: diff-liveness-dirs
#+begin_example
diff -x \*.docx -x \*.pdf -x \*generate\*.out -qru reference-20190903/ $testdir/local/ | egrep -v "(docx|pdf|generate-.*\.out) differ" > $testdir/failures-local.txt
diff -sqru reference-20190903/ $testdir/local/ > $testdir/identicals-local.txt
for binary in reference-20190903/v0.9/*.{docx,pdf};
  do filename=`basename $binary`;
     if [ $(stat -f "%z" $binary) = $(stat -f "%z" $testdir/local/v0.9/$filename) ];
        then :;
        else echo " !! file sizes differ for local/v0.9/$filename";
             ls -l $binary local/v0.9/$filename | tee failures-local-v0.9-$filename.txt; fi; done
for binary in reference-20190903/v1.0/*.{docx,pdf};
  do filename=`basename $binary`;
     if [ $(stat -f "%z" $binary) = $(stat -f "%z" $testdir/local/v1.0/$filename) ];
        then :;
        else echo " !! file sizes differ for local/v1.0/$filename";
             ls -l $binary local/v1.0/$filename | tee failures-local-v1.0-$filename.txt; fi; done
for binary in reference-20190903/v1.1/*.{docx,pdf};
  do filename=`basename $binary`;
     if [ $(stat -f "%z" $binary) = $(stat -f "%z" $testdir/local/v1.1/$filename) ];
        then :;
        else echo " !! file sizes differ for local/v1.1/$filename";
             ls -l $binary local/v1.1/$filename | tee failures-local-v1.1-$filename.txt; fi; done
onoes=""; for f in $testdir/failures-*.txt; do if [ -s $f ]; then onoes="$onoes $f"; fi; done
if [ -n "$onoes" ]; then echo "!!! tests failed! $onoes"; ls -l $testdir/failures-*.txt; echo ; cat $testdir/failures-*.txt; else echo "*** all tests passed!"; fi
#+end_example

**** Which tests failed?

If any of the ~failures-*.txt~ files are nonblank then we take it that something failed.

**** Setting up the Reference Directory

We take the 0.9, 1.0, and 1.1 outputs as the unit of comparison.

It shouldn't matter what ~LGL_URI~ endpoint we probe; we should expect the same results.

So we clean up the output dirs until they look like this:

#+BEGIN_EXAMPLE
  /Users/mengwong/src/l/npm/lglsdk/tests/reference-20190903:
  total used in directory 0 available 9223372036851515156
  drwxr-xr-x   5 staff  160 Sep  3 22:02 .
  drwxr-xr-x  19 staff  608 Sep  3 22:03 ..
  drwxr-xr-x  19 staff  608 Sep  3 21:46 v0.9
  drwxr-xr-x  18 staff  576 Sep  3 21:29 v1.0
  drwxr-xr-x  22 staff  704 Sep  3 21:29 v1.1
#+END_EXAMPLE

And we use that to diff the test-run folders against.

* Testing the library

The test suite directly calls the library functions exposed by the SDK. Most of those library functions map to back-end endpoints. The output of those function calls is compared against known expectations.

* Testing the endpoints

The server-side API endpoints are implicitly tested as part of the tests of the library and lgl executable.

In future, we could do curl-based testing if an independent channel of coverage is desired.

** Extended Endpoint Testing

Next we load in an lglconfig.json which was not created by a ~-t init~. Rather, this is an lglconfig.json which you created yourself through a normal ~lgl init~. You then signed up for a paying product plan which gives you access to more templates.

Extended testing only runs if the script is given an argument: an lglconfig.json which has access to more than just the basic templates.

#+NAME: extended_proforma_testing_top
#+BEGIN_SRC sh :noweb yes :shebang #!/bin/bash
################################################## extended endpoint testing, top
if [ "" = "$1" ]; then
  echo "*** no live lglconfig.json specified on command line; will skip extended proforma tests";
else
  echo " ** will perform extended proforma tests later"
fi

# back to basics
#+END_SRC

#+NAME: extended_proforma_testing_main
#+BEGIN_SRC sh :noweb yes :shebang #!/bin/bash
################################################## extended endpoint testing, main
if [ "" = "$1" ]; then
  echo "*** skipping extended proforma tests";
else
  echo " ** performing extended proforma tests; first, displacing $1 into lglconfig.json"
  mkdir -p extended
  cp ../../$1 extended/lglconfig.json
  cd extended

  lgl proforma schemalist > proforma-schemalist.out
  echo "*** extended proforma tests: will try to generate PDFs for " `json -ak < proforma-schemalist.out | wc -l` templates

  for templateKey in $(json -ak < proforma-schemalist.out); do
    echo " ** $templateKey"
    lgl proforma schemalist $templateKey > schemalist-$templateKey.out
    lgl proforma schemalist $templateKey example > schemalist-$templateKey-example.out
    lgl proforma validate $templateKey < schemalist-$templateKey-example.out > validate-$templateKey.out 2> validate-$templateKey.err
    lgl proforma generate $templateKey generate-$templateKey.pdf < schemalist-$templateKey-example.out > generate-$templateKey.out 2> generate-$templateKey.err

    if egrep -q 'validate.*true' < validate-$templateKey.out; then
      : # echo "  + validated $templateKey"
    else
      echo " !! validate failed for $templateKey"
      echo "\nvalidate failed for $templateKey using example input" > ../failures-extended-validate-$templateKey.txt
      cat validate-$templateKey.* >> ../failures-extended-validate-$templateKey.txt
      echo "to reproduce: lgl proforma validate $templateKey < schemalist-$templateKey-example.out" >> ../failures-extended-validate-$templateKey.txt
    fi

    if [ ! -s generate-$templateKey.pdf -o $(stat -f "%z" generate-$templateKey.pdf) = 6 ]; then
      echo "outcome unsatisfactory: lgl proforma generate $templateKey generate-$templateKey.pdf < schemalist-$templateKey-example.out" > ../failures-extended-generate-$templateKey.txt
    fi;

    # any deviation from the given template should fail validation.
    if [ "`json directors < schemalist-$templateKey-example.out 2>/dev/null`" -a \
         "`json 'directors[0].first_name' < schemalist-$templateKey-example.out`" = "William" ]; then
     # echo "  - testing deviation from example given"
      json -e 'this.directors[0].first_name = "Bill"' < schemalist-$templateKey-example.out > schemalist-$templateKey-variation.json
      lgl proforma validate $templateKey < schemalist-$templateKey-variation.json > validate-$templateKey-variation.out 2> validate-$templateKey-variation.err
      if grep -q 'need to match the example exactly' validate-$templateKey-variation.out; then
       : #  echo '  + expected variation validation failure, and got it; considering this a success!'
      else
         echo ' !! expected variation validation failure, but did not get expected error message.'
         (echo ' !! expected variation validation failure, but did not get expected error message.'; \
          cat validate-$templateKey-variation.*) > ../failures-extended-variation-validate-$templateKey.txt
      fi
    else
      : # echo "  - no deviation available -- we usually just look for a director named William we can rename to Bill"
    fi

  done;

  cd ..
fi
#+END_SRC

#+RESULTS: expanded_testing
: *** no ; skipping extended proforma tests

foreach endpoint, retrieve the example; then feed that example to validate and see if it works. feed that example to generate and see if it works.

* Emacs Notes

we use org-mode babel to tangle and execute. ~C-c C-v t~ is the big one.

You want to turn off org-confirm-babel-evaluate and add Python to org-babel-load-languages.
